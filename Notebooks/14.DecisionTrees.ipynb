{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842f1aea-7c22-4033-8a91-ccafe00d9976",
   "metadata": {},
   "source": [
    "# 14. Decision Trees\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rhennig/EMA6938/blob/main/Notebooks/14.DecisionTrees.ipynb)\n",
    "\n",
    "Slides and notebook based on https://www.datacamp.com/community/tutorials/decision-tree-classification-python, https://nanohub.org/tools/mseml/, https://machinelearningmastery.com/information-gain-and-mutual-information/.\n",
    "\n",
    "We will use the Decision Tree Classifier Building in Scikit-learn.\n",
    "\n",
    "Let's first load the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab4df68-4076-4b53-8b55-e60d2b38a9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mendeleev in /Users/rhennig/opt/anaconda3/envs/tf2/lib/python3.8/site-packages (0.9.0)\n",
      "Requirement already satisfied: pyfiglet<0.9,>=0.8.post1 in /Users/rhennig/opt/anaconda3/envs/tf2/lib/python3.8/site-packages (from mendeleev) (0.8.post1)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.4 in /Users/rhennig/opt/anaconda3/envs/tf2/lib/python3.8/site-packages (from mendeleev) (0.4.4)\n",
      "Requirement already satisfied: six<2.0.0,>=1.15.0 in /Users/rhennig/opt/anaconda3/envs/tf2/lib/python3.8/site-packages (from mendeleev) (1.16.0)\n",
      "Requirement already satisfied: Pygments<3.0.0,>=2.8.0 in /Users/rhennig/opt/anaconda3/envs/tf2/lib/python3.8/site-packages (from mendeleev) (2.10.0)\n",
      "Requirement already satisfied: pandas>=0.25.0 in /Users/rhennig/opt/anaconda3/envs/tf2/lib/python3.8/site-packages (from mendeleev) (1.3.5)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.0,>=1.3.23 in /Users/rhennig/opt/anaconda3/envs/tf2/lib/python3.8/site-packages (from mendeleev) (1.4.31)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.19.5 in /Users/rhennig/opt/anaconda3/envs/tf2/lib/python3.8/site-packages (from mendeleev) (1.22.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/rhennig/opt/anaconda3/envs/tf2/lib/python3.8/site-packages (from pandas>=0.25.0->mendeleev) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/rhennig/opt/anaconda3/envs/tf2/lib/python3.8/site-packages (from pandas>=0.25.0->mendeleev) (2021.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/rhennig/opt/anaconda3/envs/tf2/lib/python3.8/site-packages (from SQLAlchemy<2.0.0,>=1.3.23->mendeleev) (1.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Install the mendeleev package using pip in the current Jupyter kernel\n",
    "# To use them, you may need to restart the kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install mendeleev\n",
    "\n",
    "import pymatgen as pymat\n",
    "from pymatgen.core.periodic_table import Element\n",
    "import mendeleev as mendel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6795f67b-7799-4df8-9a8c-b942dd72a3fc",
   "metadata": {},
   "source": [
    "### Getting the dataset\n",
    "\n",
    "We query both Pymatgen and Mendeleev to get a complete set of properties per element. We will use this data to create the features from which the model will train and test. \n",
    "\n",
    "We select 47 elements that occur in the fcc, hcp, and bcc structure. The elements listed were chosen because querying them for these properties yields a dataset with no unknown values, and because they represent the three most common crystallographic structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c81b04-b078-4324-9582-aef95c4f7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcc_elements = [\"Ag\", \"Al\", \"Au\", \"Cu\", \"Ir\", \"Ni\", \"Pb\", \"Pd\", \"Pt\", \"Rh\", \"Th\", \"Yb\"]\n",
    "bcc_elements = [\"Ba\", \"Ca\", \"Cr\", \"Cs\", \"Eu\", \"Fe\", \"Li\", \"Mn\", \"Mo\", \"Na\", \"Nb\", \"Rb\", \"Ta\", \"V\", \"W\" ]\n",
    "hcp_elements = [\"Be\", \"Cd\", \"Co\", \"Dy\", \"Er\", \"Gd\", \"Hf\", \"Ho\", \"Lu\", \"Mg\", \"Re\", \n",
    "                \"Ru\", \"Sc\", \"Tb\", \"Ti\", \"Tl\", \"Tm\", \"Y\", \"Zn\", \"Zr\"]\n",
    "\n",
    "elements = fcc_elements + bcc_elements + hcp_elements\n",
    "\n",
    "random.Random(1).shuffle(elements)\n",
    "\n",
    "querable_mendeleev = [\"atomic_number\", \"atomic_volume\", \"boiling_point\", \"en_ghosh\",  \"evaporation_heat\", \"heat_of_formation\",\n",
    "                     \"lattice_constant\", \"melting_point\", \"specific_heat\"]\n",
    "querable_pymatgen = [\"atomic_mass\", \"atomic_radius\", \"electrical_resistivity\",\"molar_volume\", \"bulk_modulus\", \"youngs_modulus\",\n",
    "                     \"average_ionic_radius\", \"density_of_solid\", \"coefficient_of_linear_thermal_expansion\"]\n",
    "querable_values = querable_mendeleev + querable_pymatgen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8633eab5-4668-4318-a450-36b83312c452",
   "metadata": {},
   "source": [
    "We will use the database queries to populate a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4b755-a17f-4b78-a096-7648fd961282",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values = [] # Values for Attributes\n",
    "all_labels = [] # Crystal structure labels (0 = fcc, 1 = bcc, 2 = hcp)\n",
    "\n",
    "for item in elements:\n",
    "    element_values = []\n",
    "    \n",
    "    # This section queries Mendeleev\n",
    "    element_object = mendel.element(item)\n",
    "    for i in querable_mendeleev:    \n",
    "        element_values.append(getattr(element_object,i))\n",
    "\n",
    "    # This section queries Pymatgen\n",
    "    element_object = Element(item)    \n",
    "    for i in querable_pymatgen:\n",
    "        element_values.append(getattr(element_object,i))\n",
    "        \n",
    "    all_values.append(element_values) # All lists are appended to another list, creating a List of Lists\n",
    "    \n",
    "    if (item in fcc_elements):\n",
    "        all_labels.append([1, 0, 0]) # The crystal structure labels are assigned here\n",
    "    elif (item in bcc_elements):\n",
    "        all_labels.append([0, 1, 0]) # The crystal structure labels are assigned here\n",
    "    elif (item in hcp_elements):\n",
    "        all_labels.append([0, 0, 1]) # The crystal structure labels are assigned here\n",
    "\n",
    "# Pandas Dataframe\n",
    "df = pd.DataFrame(all_values, columns=querable_values)\n",
    "\n",
    "# We will patch some of the values that are not available in the datasets.\n",
    "\n",
    "# Value for the CTE of Cesium\n",
    "index_Cs = df.index[df['atomic_number'] == 55]\n",
    "df.iloc[index_Cs, df.columns.get_loc(\"coefficient_of_linear_thermal_expansion\")] = 0.000097 \n",
    "# Value from: David R. Lide (ed), CRC Handbook of Chemistry and Physics, 84th Edition. CRC Press. Boca Raton, Florida, 2003\n",
    "\n",
    "# Value for the CTE of Rubidium\n",
    "index_Rb = df.index[df['atomic_number'] == 37]\n",
    "df.iloc[index_Rb, df.columns.get_loc(\"coefficient_of_linear_thermal_expansion\")] = 0.000090 \n",
    "# Value from: https://www.azom.com/article.aspx?ArticleID=1834\n",
    "\n",
    "# Value for the Evaporation Heat of Ruthenium\n",
    "index_Ru = df.index[df['atomic_number'] == 44]\n",
    "df.iloc[index_Ru, df.columns.get_loc(\"evaporation_heat\")] = 595 # kJ/mol \n",
    "# Value from: https://www.webelements.com/ruthenium/thermochemistry.html\n",
    "\n",
    "# Value for the Bulk Modulus of Zirconium\n",
    "index_Zr = df.index[df['atomic_number'] == 40]\n",
    "df.iloc[index_Zr, df.columns.get_loc(\"bulk_modulus\")] = 94 # GPa \n",
    "# Value from: https://materialsproject.org/materials/mp-131/\n",
    "\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b86b181-cb61-450d-b92d-9fdaf993894e",
   "metadata": {},
   "source": [
    "### Processing and Organizing Data\n",
    "\n",
    "We normalize the data and randomly split it into training and testing sets.\n",
    "\n",
    "##### SETS\n",
    "\n",
    "We have 47 elements for which the crystal structure is known and we will use 40 of these as a training set and the remaining 7 as testing set.\n",
    "\n",
    "##### NORMALIZATION\n",
    "\n",
    "We will again use the Standard Score Normalization, which subtracts the mean of the feature and divide by its standard deviation.\n",
    "$$\n",
    "\\frac{X - µ}{σ}\n",
    "$$\n",
    "While our model might converge without feature normalization, the resultant model would be difficult to train and would be dependent on the choice of units used in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a27eec3-c8cd-44d2-bfc3-b14c1a090c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETS\n",
    "all_values = [list(df.iloc[x]) for x in range(len(all_values))]\n",
    "\n",
    "# List of lists are turned into Numpy arrays to facilitate calculations in steps to follow\n",
    "# (Normalization).\n",
    "all_values = np.array(all_values, dtype = float)\n",
    "print(\"Shape of Values:\", all_values.shape)\n",
    "all_labels = np.array(all_labels, dtype = int)\n",
    "print(\"Shape of Labels:\", all_labels.shape)\n",
    "\n",
    "# Training Set\n",
    "train_values = all_values[:40, :]\n",
    "train_labels = all_labels[:40, :]\n",
    "\n",
    "# Testing Set\n",
    "test_values = all_values[-7:, :]\n",
    "test_labels = all_labels[-7:, :]\n",
    "\n",
    "# NORMALIZATION\n",
    "\n",
    "mean = np.nanmean(train_values, axis = 0) # mean\n",
    "std = np.nanstd(train_values, axis = 0) # standard deviation\n",
    "\n",
    "train_values = (train_values - mean) / std # input scaling\n",
    "test_values = (test_values - mean) / std # input scaling\n",
    "\n",
    "print(train_values[0]) # print a sample entry from the training set\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f1b150-a627-4f74-8aed-f11793c257ab",
   "metadata": {},
   "source": [
    "### Creating the Decision Tree Model\n",
    "\n",
    "For this classification, we will use a simple decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b172d57-a29b-425f-b57d-f23e2b586639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "model.fit(train_values, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c910f-5042-4031-b966-622a60bdafb0",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "We calculate the accuracy score on the training and the testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81539e2-84ef-47b3-88f4-34961e9ccb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for training and testing dataset\n",
    "train_pred = model.predict(train_values)\n",
    "test_pred = model.predict(test_values)\n",
    "\n",
    "# Model Accuracy for training and testing set, how often is the classifier correct?\n",
    "\n",
    "print('Training accuracy = %.3f ' % accuracy_score(train_labels, train_pred))\n",
    "print('Testing accuracy  = %.3f ' % accuracy_score(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fc4e5-f037-4896-b314-e2688f2640b4",
   "metadata": {},
   "source": [
    "### Visualize the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e3bb55-e392-4320-8ffd-29704c6641f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(model, feature_names=querable_values, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7847ea93-9653-4b3e-b1b9-cfdaea50c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(train_values)\n",
    "test_predictions = model.predict(test_values)\n",
    "\n",
    "all_labels = np.vstack((train_labels, test_labels))\n",
    "all_predictions = np.vstack((train_predictions, test_predictions))\n",
    "\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "for i in range(all_predictions.shape[0]):\n",
    "    if (np.argmax(all_predictions[i]) == 0):\n",
    "        predicted_labels.append(\"FCC\")\n",
    "    if (np.argmax(all_labels[i]) == 0):\n",
    "        true_labels.append(\"FCC\")\n",
    "    if (np.argmax(all_predictions[i]) == 1):\n",
    "        predicted_labels.append(\"BCC\")\n",
    "    if (np.argmax(all_labels[i]) == 1):\n",
    "        true_labels.append(\"BCC\")\n",
    "    if (np.argmax(all_predictions[i]) == 2):\n",
    "        predicted_labels.append(\"HCP\")\n",
    "    if (np.argmax(all_labels[i]) == 2):\n",
    "        true_labels.append(\"HCP\")\n",
    "\n",
    "predicted_labels = np.array(predicted_labels).reshape((-1, 1))\n",
    "true_labels = np.array(true_labels).reshape((-1, 1))\n",
    "headings = [\"Atomic number\", \"True crystal structure\", \"Predicted crystal structure\"]\n",
    "\n",
    "atomic_number_array = np.array(df.iloc[:, 0]).reshape((-1, 1))\n",
    "plot_table = np.concatenate((atomic_number_array, true_labels, predicted_labels), axis=1)\n",
    "\n",
    "plot_df = pd.DataFrame(plot_table, columns=headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e3d55-33ec-4b2c-93d7-ebfbfcd3e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cae7e1e-1064-49da-829d-e35f2e3dbed7",
   "metadata": {},
   "source": [
    "### Optimization of the decision tree\n",
    "\n",
    "The default Attribute Selection Measure to determine the quality of a split for a decision node is Gini. We can try the Entropy measure and also see if we can reduce the depths of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6201271c-7260-4eb1-9573-11a5b1de171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "model.fit(train_values, train_labels)\n",
    "\n",
    "#Predict the response for training and testing dataset\n",
    "train_pred = model.predict(train_values)\n",
    "test_pred = model.predict(test_values)\n",
    "\n",
    "# Model Accuracy for training and testing set, how often is the classifier correct?\n",
    "\n",
    "print('Training accuracy = %.3f ' % accuracy_score(train_labels, train_pred))\n",
    "print('Testing accuracy  = %.3f ' % accuracy_score(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a2b1b-13ed-46d3-a713-545d2af6305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(model, feature_names=querable_values, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2bc58-d201-4805-8012-f25775aa99b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
